{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"/home/niyiyu/notebooks/DASStore\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pyasdf\n",
    "from datetime import datetime, timedelta\n",
    "import h5py\n",
    "import numpy as np\n",
    "import DAS_module\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dasstore.zarr import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No credential found for endpoint s3.us-west-2.amazonaws.com'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/niyiyu/Research/SeaDASCorr/NoisePy4DAS-SeaDAS/notebooks/dev_test_noisepy4das_dasstore.ipynb Cell 2\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsermeq.ess.washington.edu/home/niyiyu/Research/SeaDASCorr/NoisePy4DAS-SeaDAS/notebooks/dev_test_noisepy4das_dasstore.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m role_assigned \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsermeq.ess.washington.edu/home/niyiyu/Research/SeaDASCorr/NoisePy4DAS-SeaDAS/notebooks/dev_test_noisepy4das_dasstore.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# prepare client and time range\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsermeq.ess.washington.edu/home/niyiyu/Research/SeaDASCorr/NoisePy4DAS-SeaDAS/notebooks/dev_test_noisepy4das_dasstore.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m client \u001b[39m=\u001b[39m Client(bucket, endpoint, secure \u001b[39m=\u001b[39;49m secure, credential_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m~/.aws/credentials\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/notebooks/DASStore/dasstore/zarr/client.py:33\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, bucket, endpoint, region, secure, anon, role_assigned, credential_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcredential \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m anon:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcredential \u001b[39m=\u001b[39m get_credential(endpoint, credential_path)\n\u001b[1;32m     34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcredential[\u001b[39m\"\u001b[39m\u001b[39maws_access_key_id\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39msecret\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcredential[\u001b[39m\"\u001b[39m\u001b[39maws_secret_access_key\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/notebooks/DASStore/dasstore/utils/credential.py:31\u001b[0m, in \u001b[0;36mget_credential\u001b[0;34m(endpoint, credential_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m creds[endpoint]\n\u001b[1;32m     30\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo credential found for endpoint \u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No credential found for endpoint s3.us-west-2.amazonaws.com'"
     ]
    }
   ],
   "source": [
    "# client information\n",
    "bucket = \"seadas-december-2022\"\n",
    "endpoint = \"s3.us-west-2.amazonaws.com\"\n",
    "secure = True\n",
    "role_assigned = True\n",
    "\n",
    "# prepare client and time range\n",
    "client = Client(bucket, endpoint, secure = secure, credential_path=\"~/.aws/credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful parameters for preprocessing the data\n",
    "input_fmt = 'zarr'                                                      # input file format between 'sac' and 'mseed' \n",
    "sps       = 100                                                         # current sampling rate\n",
    "samp_freq = 50                                                          # targeted sampling rate\n",
    "freqmin   = 1                                                          # pre filtering frequency bandwidth\n",
    "freqmax   = 20                                                          # note this cannot exceed Nquist freq\n",
    "flag      = True                                                        # print intermediate variables and computing time\n",
    "gaug_len  = 2                                                           # gauge length of the array for inter-station distance (assuming linear array)\n",
    "\n",
    "# useful parameters for cross correlating the data\n",
    "freq_norm   = 'phase_only'                                                     # 'no' for no whitening, or 'rma' for running-mean average, 'phase_only' for sign-bit normalization in freq domain.\n",
    "time_norm   = 'one_bit'                                                 # 'no' for no normalization, or 'rma', 'one_bit' for normalization in time domain\n",
    "cc_method   = 'xcorr'                                                   # 'xcorr' for pure cross correlation, 'deconv' for deconvolution; FOR \"COHERENCY\" PLEASE set freq_norm to \"rma\", time_norm to \"no\" and cc_method to \"xcorr\"\n",
    "smooth_N    = 100                                                       # moving window length for time domain normalization if selected (points)\n",
    "smoothspect_N  = 100                                                    # moving window length to smooth spectrum amplitude (points)\n",
    "maxlag      = 10                                                        # lags of cross-correlation to save (sec)\n",
    "\n",
    "# criteria for data selection\n",
    "max_over_std = 10                                                       # threahold to remove window of bad signals: set it to 10*9 if prefer not to remove them\n",
    "\n",
    "# maximum memory allowed per core in GB\n",
    "MAX_MEM   = 4.0        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_len = 60\n",
    "step   = 60\n",
    "\n",
    "N_NODE = 10\n",
    "NODE_ID = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = datetime.fromisoformat(client.meta['acquisition.acquisition_start_time']).date()\n",
    "t1 = datetime.fromisoformat(client.meta['acquisition.acquisition_end_time']).date()\n",
    "n_days = (t1 - t0 + timedelta(days=1)).days\n",
    "date_list = [t0 + timedelta(days = i) for i in range(n_days)]\n",
    "split = np.array_split(date_list, N_NODE)[NODE_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one sample file to get some basic parameters\n",
    "cha_list = np.array(range(500, 1100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCFDIR = \"/home/niyiyu/Research/SeaDASCorr/DASStore_CCF\"\n",
    "prepro_para = {'CCFDIR':CCFDIR,\n",
    "               'input_fmt':input_fmt,\n",
    "               'freqmin':freqmin,\n",
    "               'freqmax':freqmax,\n",
    "               'sps':sps,\n",
    "               'npts_chunk':cc_len*sps,\n",
    "               'nsta':len(cha_list),\n",
    "               'cha_list':cha_list,\n",
    "               'samp_freq':samp_freq,\n",
    "            #    'allfiles_path':rootpath,\n",
    "               'freq_norm':freq_norm,\n",
    "               'time_norm':time_norm,\n",
    "               'cc_method':cc_method,\n",
    "               'smooth_N':smooth_N,\n",
    "               'smoothspect_N':smoothspect_N,\n",
    "               'maxlag':maxlag,\n",
    "               'max_over_std':max_over_std,\n",
    "               'MAX_MEM':MAX_MEM}\n",
    "metadata = os.path.join(CCFDIR,'prepro_fft_info.txt')\n",
    "# output parameter info\n",
    "fout = open(metadata,'w')\n",
    "fout.write(str(prepro_para));fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-08 00:00:00 2022-12-09 00:00:00\n",
      "2022-12-09 00:00:00 2022-12-10 00:00:00\n",
      "2022-12-10 00:00:00 2022-12-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for i in split:\n",
    "    # one node\n",
    "    node_t0 = datetime(year = i.year, month = i.month, day = i.day, \n",
    "                       hour = 0, minute = 0, second = 0, microsecond=0)\n",
    "    node_t1 = datetime(year = i.year, month = i.month, day = i.day + 1, \n",
    "                    hour = 0, minute = 0, second = 0, microsecond=0)\n",
    "\n",
    "    print(node_t0, node_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ick = 0\n",
    "tdata = client.get_data(cha_list, \n",
    "            starttime = node_t0,\n",
    "            endtime = node_t0 + timedelta(minutes = 1)).T\n",
    "# temp  = allfiles[ick].split('/')[-1].split('_')\n",
    "# tvec  = str(temp[3]+temp[4].split('.')[0])\n",
    "# print(tvec)\n",
    "\n",
    "# perform pre-processing\n",
    "trace_stdS,dataS = DAS_module.preprocess_raw_make_stat(tdata,prepro_para)\n",
    "\n",
    "# do normalization if needed\n",
    "white_spect = DAS_module.noise_processing(dataS,prepro_para)\n",
    "Nfft = white_spect.shape[1];Nfft2 = Nfft//2\n",
    "\n",
    "# load fft data in memory for cross-correlations\n",
    "data = white_spect[:,:Nfft2]\n",
    "del dataS,white_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove channel of potential local traffic noise\n",
    "ind = np.where((trace_stdS<prepro_para['max_over_std']) &\n",
    "                (trace_stdS>0) &\n",
    "                (np.isnan(trace_stdS)==0))[0]\n",
    "if not len(ind):\n",
    "    raise ValueError('the max_over_std criteria is too high which results in no data')\n",
    "sta = cha_list[ind]\n",
    "white_spect = data[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftmp = open(CCFDIR + \"/tmp.log\",'w')\n",
    "for iiS in range(len(sta)-1):\n",
    "# for iiS in range(3):\n",
    "    sfft1 = DAS_module.smooth_source_spect(white_spect[iiS],prepro_para)\n",
    "    corr,tindx = DAS_module.correlate(sfft1,white_spect[iiS+1:],prepro_para,Nfft)\n",
    "    # update the receiver list\n",
    "    tsta = sta[iiS+1:]\n",
    "    receiver_lst = sta[tindx]\n",
    "\n",
    "    # save cross-correlation into ASDF file\n",
    "    for iiR in range(len(receiver_lst)):\n",
    "        with pyasdf.ASDFDataSet(CCFDIR + \"/test.h5\", mpi=False) as ccf_ds:\n",
    "            # use the channel number as a way to figure out distance\n",
    "            Rindx = np.where(sta==receiver_lst[iiR])[0]\n",
    "            Sindx = iiS\n",
    "            param = {'dist':int(Rindx-Sindx)*gaug_len,\n",
    "                    'sps':samp_freq,\n",
    "                    'dt': 1/samp_freq,\n",
    "                    'maxlag':maxlag,\n",
    "                    'freqmin':freqmin,\n",
    "                    'freqmax':freqmax}\n",
    "        \n",
    "            # source-receiver pair\n",
    "            data_type = str(sta[iiS])\n",
    "            path = str(sta[iiS])+'_'+str(receiver_lst[iiR])\n",
    "            ccf_ds.add_auxiliary_data(data=corr[iiR], \n",
    "                                        data_type=data_type, \n",
    "                                        path=path, \n",
    "                                        parameters=param)\n",
    "            ftmp.write(str(sta[iiS])+'_'+str(receiver_lst[iiR])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('das')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "907bd4c1fa87656fede542979b349e88f5e00128b8aff9cf96746d64605b1c31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
